# 더 나은 베이지안 필터링 (Better Bayesian Filtering)

2003년 1월

(이 글은 2003년 스팸 컨퍼런스에서 발표된 내용입니다. 제가 '스팸에 대한 계획 (A Plan for Spam)'에 설명된 알고리즘의 성능을 개선하기 위해 수행한 작업과 앞으로의 계획에 대해 기술합니다.)

여기서 제가 처음으로 제시하고 싶은 발견은 연구 논문의 지연 평가 (lazy evaluation) 알고리즘입니다. 원하는 대로 쓰고 이전 작업을 인용하지 않으면, 분개한 독자들이 인용했어야 할 모든 논문에 대한 레퍼런스를 보내줄 것입니다. 저는 '스팸에 대한 계획 (A Plan for Spam)' [1]이 슬래시닷 (Slashdot)에 올라온 후에 이 알고리즘을 발견했습니다.

스팸 필터링은 텍스트 분류 (text classification)의 하위 집합이며, 이는 잘 정립된 분야입니다. 하지만 베이지안 스팸 필터링 자체에 대한 첫 논문은 1998년 같은 컨퍼런스에서 발표된 판텔 (Pantel)과 린 (Lin) [2]의 논문과 마이크로소프트 리서치 (Microsoft Research) 그룹의 논문 [3]으로 보입니다. 이 연구에 대해 들었을 때 저는 약간 놀랐습니다. 4년 전부터 사람들이 베이지안 필터링을 사용하고 있었다면, 왜 모두가 그것을 사용하지 않았을까요?

논문을 읽어보니 그 이유를 알 수 있었습니다. 판텔과 린의 필터는 두 가지 중 더 효과적이었지만, 스팸의 92%만 걸러냈고 오탐 (false positive)률은 1.16%였습니다. 제가 베이지안 스팸 필터를 작성했을 때, 스팸의 99.5%를 걸러냈고 오탐률은 0.03% 미만이었습니다 [4].

두 사람이 같은 실험을 시도하여 매우 다른 결과를 얻을 때는 항상 놀랍습니다. 특히 이 두 가지 수치 집합이 상반된 결론을 내릴 수 있기 때문에 더욱 그렇습니다. 사용자마다 요구 사항이 다르지만, 많은 사람들에게 1.16%의 오탐률로 92%의 필터링률은 필터링이 수용 가능한 해결책이 아님을 의미하는 반면, 0.03% 미만의 오탐률로 99.5%는 수용 가능한 해결책임을 의미한다고 생각합니다.

그렇다면 왜 우리는 이렇게 다른 수치를 얻었을까요? 저는 판텔과 린의 결과를 재현하려고 시도하지는 않았지만, 논문을 읽어보니 그 차이를 설명할 수 있는 다섯 가지가 보입니다.

하나는 단순히 그들이 필터를 매우 적은 데이터로 학습시켰다는 것입니다: 스팸 메일 160개와 비스팸 메일 466개. 그렇게 작은 데이터 세트로는 필터 성능이 여전히 향상되고 있어야 합니다. 따라서 그들의 수치는 베이지안 스팸 필터링 전반은 물론, 그들의 알고리즘 성능에 대한 정확한 측정치도 아닐 수 있습니다.

하지만 가장 중요한 차이는 아마도 그들이 메시지 헤더 (message header)를 무시했다는 점일 것입니다. 스팸 필터 작업을 해본 사람에게는 이것이 비정상적인 결정으로 보일 것입니다. 그런데 제가 처음 작성했던 필터에서도 헤더를 무시했습니다. 왜 그랬을까요? 문제를 깔끔하게 유지하고 싶었기 때문입니다. 저는 그때 메일 헤더에 대해 잘 몰랐고, 무작위적인 내용으로 가득 찬 것처럼 보였습니다. 필터 개발자들에게는 여기서 얻을 수 있는 교훈이 있습니다: 데이터를 무시하지 마세요. 이 교훈은 너무나 명백해서 언급할 필요도 없다고 생각하겠지만, 저는 여러 번 배워야 했습니다.

셋째, 판텔과 린은 토큰 (token)을 어간 추출 (stemming)했습니다. 즉, 'mailing'과 'mailed'를 모두 'mail'이라는 어근으로 축소했습니다. 그들은 코퍼스 (corpus)의 크기가 작았기 때문에 어쩔 수 없이 이렇게 했을 수도 있지만, 그렇다면 이것은 일종의 조기 최적화 (premature optimization)입니다.

넷째, 그들은 확률을 다르게 계산했습니다. 그들은 모든 토큰을 사용했지만, 저는 가장 중요한 15개의 토큰만 사용했습니다. 모든 토큰을 사용하면 누군가가 다단계 마케팅 (multilevel marketing)으로 부자가 된 자신의 인생 이야기를 들려주는 유형의 긴 스팸을 놓치는 경향이 있습니다. 또한, 스패머 (spammer)가 스팸 용어의 균형을 맞추기 위해 무작위 텍스트를 많이 추가하는 방식으로 이런 알고리즘을 쉽게 속일 수 있습니다.

마지막으로, 그들은 오탐을 줄이기 위한 편향 (bias)을 두지 않았습니다. 저는 어떤 스팸 필터링 알고리즘이든 필터링률을 희생하여 오탐률을 줄일 수 있는 편리한 조절 장치 (knob)가 있어야 한다고 생각합니다. 저는 비스팸 코퍼스에서 토큰의 발생 횟수를 두 배로 계산하여 이를 수행합니다.

저는 스팸 필터링을 단순한 텍스트 분류 문제로 취급하는 것이 좋지 않다고 생각합니다. 텍스트 분류 기술을 사용할 수 있지만, 해결책은 해당 텍스트가 이메일, 특히 스팸이라는 사실을 반영해야 하며 그렇게 할 수 있습니다. 이메일은 단순한 텍스트가 아닙니다; 구조를 가지고 있습니다. 스팸 필터링은 단순한 분류가 아닙니다. 왜냐하면 오탐은 미탐 (false negative)보다 훨씬 나쁘기 때문에 다른 종류의 오류로 취급해야 합니다. 그리고 오류의 원인은 단순히 무작위 변동이 아니라, 필터를 무력화하기 위해 적극적으로 노력하는 실제 스패머입니다.

## 토큰 (Tokens)

슬래시닷 기사 이후 제가 들었던 또 다른 프로젝트는 빌 예라주니스 (Bill Yerazunis)의 CRM114 [5]였습니다. 이것은 제가 방금 언급한 설계 원칙의 반례입니다. 이것은 단순한 텍스트 분류기이지만, 너무나 놀랍도록 효과적이어서 자신이 무엇을 하고 있는지조차 알지 못하면서도 스팸을 거의 완벽하게 필터링합니다.

CRM114가 어떻게 작동하는지 이해한 후, 저는 결국 단일 단어 기반 필터링에서 이와 같은 접근 방식으로 이동해야 할 것이라고 생각했습니다. 하지만 먼저, 단일 단어만으로 어디까지 갈 수 있는지 보려고 했습니다. 그리고 답은 놀랍도록 멀리 갈 수 있다는 것입니다.

주로 저는 더 스마트한 토큰화 (tokenization)에 힘써 왔습니다. 현재 스팸에 대해 CRM114에 근접하는 필터링률을 달성할 수 있었습니다. 이 기술들은 빌의 기술과 대부분 직교 (orthogonal)합니다. 최적의 해결책은 둘 다 통합할 수도 있습니다.

'스팸에 대한 계획 (A Plan for Spam)'은 토큰에 대한 매우 간단한 정의를 사용합니다. 문자, 숫자, 하이픈, 아포스트로피, 달러 기호는 구성 문자이며, 나머지는 모두 토큰 구분자입니다. 또한 저는 대소문자를 무시했습니다.

이제 토큰에 대한 더 복잡한 정의를 사용합니다:
* 대소문자가 유지됩니다.
* 느낌표는 구성 문자입니다.
* 마침표와 쉼표는 두 숫자 사이에 있을 경우 구성 문자입니다. 이를 통해 IP 주소와 가격을 온전히 얻을 수 있습니다.
* '$20-25'와 같은 가격 범위는 '$20'과 '$25' 두 개의 토큰을 생성합니다.
* 'To', 'From', 'Subject', 'Return-Path' 줄 또는 URL 내에 나타나는 토큰은 그에 따라 표시됩니다. 예를 들어, Subject 줄의 'foo'는 'Subject*foo'가 됩니다. (별표는 구성 문자로 허용하지 않는 모든 문자일 수 있습니다.)

이러한 조치는 필터의 어휘를 증가시켜 더 식별력 (discriminating)을 높입니다. 예를 들어, 현재 필터에서 Subject 줄의 'free'는 스팸 확률이 98%인 반면, 본문의 동일한 토큰은 스팸 확률이 65%에 불과합니다.

현재 확률 중 일부는 다음과 같습니다 [6]:
Subject*FREE: 0.9999
free!!: 0.9999
To*free: 0.9998
Subject*free: 0.9782
free!: 0.9199
Free: 0.9198
Url*free: 0.9091
FREE: 0.8747
From*free: 0.7636
free: 0.6546

'스팸에 대한 계획 (Plan for Spam)' 필터에서는 이 모든 토큰이 0.7602라는 동일한 확률을 가졌을 것입니다. 그 필터는 약 23,000개의 토큰을 인식했습니다. 현재 필터는 약 187,000개를 인식합니다.

더 큰 토큰의 범위를 갖는 단점은 놓칠 가능성이 더 많다는 것입니다. 코퍼스를 더 많은 토큰에 분산시키는 것은 코퍼스를 더 작게 만드는 것과 같은 효과를 줍니다. 예를 들어, 느낌표를 구성 문자로 간주하면, 'free'가 두 개의 느낌표만으로도 99.99%의 확률을 가짐에도 불구하고 일곱 개의 느낌표가 있는 'free'에 대한 스팸 확률을 갖지 못할 수도 있습니다.

이에 대한 한 가지 해결책은 제가 퇴화 (degeneration)라고 부르는 것입니다. 토큰에 대한 정확한 일치 (exact match)를 찾을 수 없으면, 덜 구체적인 버전인 것처럼 처리합니다. 저는 마지막 느낌표, 대문자, 그리고 다섯 가지 표시된 맥락 중 하나에 나타나는 것을 토큰을 더 구체적으로 만드는 것으로 간주합니다. 예를 들어, 'Subject*free!'에 대한 확률을 찾을 수 없으면, 'Subject*free', 'free!', 'free'에 대한 확률을 찾아 0.5에서 가장 먼 것을 선택합니다.

필터가 Subject 줄에서 'FREE!!!'를 보고 확률을 갖고 있지 않을 때 고려되는 대안은 다음과 같습니다 [7]:
Subject*Free!!!
Subject*free!!!
Subject*FREE!
Subject*Free!
Subject*free!
Subject*FREE
Subject*Free
Subject*free
FREE!!!
Free!!!
free!!!
FREE!
Free!
free!
FREE
Free
free

이렇게 할 때는 첫 글자가 대문자인 버전과 함께 모든 글자가 대문자인 버전, 모든 글자가 소문자인 버전도 반드시 고려해야 합니다. 스팸은 명령형 (imperative mood) 문장이 더 많은 경향이 있으며, 이 경우 첫 단어가 동사입니다. 따라서 첫 글자가 대문자인 동사는 모든 글자가 소문자인 동사보다 더 높은 스팸 확률을 가집니다. 제 필터에서 'Act'의 스팸 확률은 98%이고, 'act'는 62%에 불과합니다.

필터의 어휘를 늘리면, 예전의 '같다'는 정의에 따라 같은 단어를 여러 번 세는 결과를 초래할 수 있습니다. 논리적으로는 더 이상 같은 토큰이 아닙니다. 하지만 이것이 여전히 신경 쓰인다면, 제가 경험상 덧붙이자면 여러 번 세고 있는 것처럼 보이는 단어들은 정확히 그렇게 세고 싶을 만한 단어들입니다.

더 큰 어휘의 또 다른 효과는 들어오는 메일을 볼 때 더 흥미로운 토큰을 많이 발견한다는 것입니다. 즉, 0.5에서 멀리 떨어진 확률을 가진 토큰을 말합니다. 저는 메일이 스팸인지 결정하기 위해 가장 흥미로운 15개를 사용합니다.

하지만 이런 고정된 숫자를 사용할 때 문제가 발생할 수 있습니다. 최대한 흥미로운 토큰을 많이 찾으면, 동일하게 흥미로운 토큰의 순서를 결정하는 무작위 요인에 의해 결과가 결정될 수 있습니다.

이것을 다루는 한 가지 방법은 일부를 다른 것보다 더 흥미롭게 취급하는 것입니다. 예를 들어, 'dalco'라는 토큰은 제 스팸 코퍼스에서는 3번 나타나고 합법적인 코퍼스에서는 한 번도 나타나지 않습니다. 'Url*optmails' (URL 내의 'optmails'를 의미)라는 토큰은 1223번 나타납니다. 하지만 제가 토큰에 대한 확률을 계산하던 방식으로는 둘 다 동일한 스팸 확률인 0.99의 임계값을 가질 것입니다. 이것은 옳지 않다고 느껴집니다. 이 두 토큰에 실질적으로 다른 확률을 부여해야 한다는 이론적인 주장도 있지만 (판텔과 린은 그렇게 합니다), 저는 아직 시도해보지 않았습니다.

적어도 스팸 코퍼스 또는 합법적인 코퍼스 중 하나에만 나타나는 15개 이상의 토큰을 발견했다면, 많이 나타나는 토큰에 우선순위를 부여해야 할 것 같습니다. 그래서 이제 두 개의 임계값이 있습니다. 스팸 코퍼스에만 나타나는 토큰의 경우, 10번 이상 나타나면 0.9999, 그렇지 않으면 0.9998의 확률을 가집니다. 합법적인 코퍼스에서만 발견되는 토큰의 경우도 마찬가지입니다.

나중에 토큰 확률을 실질적으로 조정할 수도 있지만, 이 아주 작은 조정만으로도 토큰이 올바른 방식으로 정렬되도록 보장합니다.

또 다른 가능성은 15개의 토큰뿐만 아니라 특정 흥미도 임계값을 넘는 모든 토큰을 고려하는 것입니다. 스티븐 하우저 (Steven Hauser)는 그의 통계적 스팸 필터 [8]에서 이를 수행합니다. 임계값을 사용한다면, 매우 높게 설정해야 합니다. 그렇지 않으면 스패머가 메시지를 더 많은 무해한 단어로 채워서 필터를 속일 수 있습니다.

마지막으로, HTML은 어떻게 처리해야 할까요? 저는 무시하는 것부터 모든 것을 파싱 (parsing)하는 것까지 모든 옵션을 시도해 보았습니다. HTML을 무시하는 것은 좋지 않습니다. 유용한 스팸 신호로 가득 차 있기 때문입니다. 하지만 모든 것을 파싱하면 필터가 단순히 HTML 인식기로 퇴화할 수 있습니다. 가장 효과적인 접근 방식은 일부 토큰은 인식하되 다른 토큰은 무시하는 중간 방식인 것 같습니다. 저는 `<a>`, `<img>`, `<font>` 태그를 보고 나머지는 무시합니다. 링크와 이미지는 URL을 포함하고 있으므로 확실히 살펴봐야 합니다.

HTML 처리에 대해 더 스마트하게 할 수 있을 것 같지만, 여기에 많은 시간을 투자할 가치는 없다고 생각합니다. HTML로 가득 찬 스팸은 필터링하기 쉽습니다. 더 똑똑한 스패머들은 이미 HTML을 피합니다. 따라서 미래의 성능은 HTML을 어떻게 처리하는지에 크게 의존하지 않을 것입니다.

## 성능 (Performance)

2002년 12월 10일부터 2003년 1월 10일까지 약 1750통의 스팸을 받았습니다. 이 중 4통이 통과되었습니다. 이는 약 99.75%의 필터링률입니다.

제가 놓친 4통의 스팸 중 2통은 제 합법적인 이메일에 자주 나타나는 단어를 사용했기 때문에 통과되었습니다.

세 번째는 안전하지 않은 CGI 스크립트를 이용하여 제3자에게 메일을 보내는 유형 중 하나였습니다. 헤더는 무해하고 사용하는 단어에 주의를 기울이기 때문에 내용만으로 필터링하기 어렵습니다. 그럼에도 불구하고 저는 보통 그들을 잡아낼 수 있습니다. 이 한 통은 0.88의 확률로 겨우 통과되었는데, 이는 임계값인 0.9보다 약간 낮았습니다. 물론, 여러 토큰 시퀀스를 보면 쉽게 잡아낼 수 있을 것입니다. "아래는 귀하의 피드백 양식 결과입니다."라는 문구는 즉각적인 신호입니다.

네 번째 스팸은 제가 미래의 스팸이라고 부르는 유형이었습니다. 스팸이 궁극적으로 이런 형태로 진화할 것이라고 예상하기 때문입니다: 완전히 중립적인 텍스트 뒤에 URL이 붙는 형태. 이 경우, 누군가가 마침내 자신의 홈페이지를 완성했고 제가 가서 봐줄 수 있는지 묻는 내용이었습니다. (그 페이지는 물론 음란물 사이트 광고였습니다.)

스패머가 헤더에 주의를 기울이고 새로운 URL을 사용한다면, 미래의 스팸에는 필터가 알아챌 만한 것이 아무것도 없습니다. 물론 크롤러를 보내 페이지를 확인할 수도 있습니다. 하지만 그럴 필요는 없을 수도 있습니다. 미래의 스팸에 대한 응답률은 낮을 것입니다. 그렇지 않다면 모두가 그렇게 할 테니까요. 충분히 낮다면, 스패머가 보낼 가치가 없을 것이고, 우리는 그것을 필터링하기 위해 너무 열심히 노력할 필요가 없을 것입니다.

이제 정말 충격적인 소식입니다: 같은 한 달 동안 세 통의 오탐 (false positive)을 받았습니다.

어떤 면에서는 오탐이 발생해서 안심이 됩니다. 제가 '스팸에 대한 계획 (A Plan for Spam)'을 작성했을 때는 오탐이 전혀 없었고, 어떤 종류일지 알 수 없었습니다. 이제 몇 번 경험하고 나니, 제가 걱정했던 것만큼 나쁘지 않다는 것을 알고 안심이 됩니다.

통계적 필터에 의해 발생하는 오탐은 스팸과 매우 유사하게 들리는 메일로 판명되며, 이런 메일들은 놓쳐도 가장 신경 쓰이지 않을 만한 것들인 경향이 있습니다 [9]. 두 통의 오탐은 제가 물건을 구매했던 회사들의 뉴스레터였습니다. 저는 그것들을 받겠다고 요청한 적이 없었으므로, 논쟁의 여지는 있지만 스팸이었다고 볼 수 있습니다. 하지만 저는 이전에 스팸으로 삭제하지 않았기 때문에 오탐으로 간주합니다. 필터가 그것들을 잡은 이유는 두 회사 모두 1월에 자체 서버에서 메일을 보내는 대신 상업적인 이메일 발송자를 사용하기 시작했고, 헤더와 본문 모두 훨씬 더 스팸스러워졌기 때문입니다.

세 번째 오탐은 나쁜 것이었습니다. 이집트에서 온 메일이었고 모두 대문자로 작성되었습니다. 이것은 토큰을 대소문자 구분하게 만든 직접적인 결과였습니다. '스팸에 대한 계획 (Plan for Spam)' 필터는 이것을 잡아내지 못했을 것입니다.

전체 오탐률이 얼마인지는 말하기 어렵습니다. 통계적으로 노이즈 수준에 있기 때문입니다. 필터 (적어도 효과적인 필터) 작업을 해본 사람이라면 이 문제를 알고 있을 것입니다. 어떤 이메일은 스팸인지 아닌지 말하기 어렵고, 필터를 정말 빡빡하게 설정했을 때 결국 이런 이메일을 보게 됩니다. 예를 들어, 지금까지 필터는 오타 때문에 제 주소로 전송된 두 통의 이메일과 제가 다른 사람이라고 믿고 저에게 전송된 한 통의 이메일을 잡았습니다. 논쟁의 여지는 있지만, 이것들은 제 스팸도, 제 비스팸 메일도 아닙니다.

또 다른 오탐은 Virtumundo의 부사장으로부터 온 것이었습니다. 제가 고객인 척 그들에게 글을 썼고, 답장이 Virtumundo의 메일 서버를 통해 왔기 때문에 상상할 수 있는 가장 유죄의 헤더를 가지고 있었습니다. 논쟁의 여지는 있지만, 이것도 실제 오탐은 아닙니다. 일종의 하이젠베르크 불확정성 원리 (Heisenberg uncertainty effect)입니다: 제가 스팸 필터링에 대해 글을 쓰고 있었기 때문에 받은 것뿐입니다.

이것들을 제외하고, 저는 지금까지 약 7740통의 합법적인 이메일 중 총 5통의 오탐을 경험했습니다. 이는 0.06%의 비율입니다. 나머지 두 통은 제가 구매한 물건이 백오더 (back-ordered)되었다는 통지와 Evite에서 온 파티 알림이었습니다. 이 수치는 신뢰할 수 없다고 생각합니다. 표본이 너무 작고, 이 중 일부는 필터가 잡지 않도록 수정할 수 있다고 생각하기 때문입니다.

오탐은 미탐과는 다른 종류의 오류라고 생각합니다. 필터링률은 성능 측정입니다. 오탐은 버그 (bug)에 가깝다고 생각합니다. 필터링률 개선은 최적화 (optimization)로 접근하고, 오탐 감소는 디버깅 (debugging)으로 접근합니다.

따라서 이 다섯 통의 오탐은 제 버그 목록입니다. 예를 들어, 이집트에서 온 메일은 대문자 텍스트 때문에 필터가 나이지리아 스팸처럼 보이게 만들었기 때문에 걸렸습니다. 이것은 정말 일종의 버그입니다. HTML과 마찬가지로, 이메일이 모두 대문자인 것은 실제로 개념적으로 하나의 기능이지, 각 단어마다 하나씩 있는 것이 아닙니다. 대소문자를 더 정교하게 처리해야 합니다.

그렇다면 이 0.06%를 어떻게 봐야 할까요? 별로 중요하지 않다고 생각합니다. 작은 표본 크기를 염두에 두고 상한선으로 취급할 수도 있습니다. 하지만 이 단계에서는 베이지안 필터링의 본질적인 오탐률이라기보다는 제 구현의 버그를 측정한 것에 가깝습니다.

## 미래 (Future)

다음은 무엇일까요? 필터링은 최적화 문제입니다. 그리고 최적화의 핵심은 프로파일링 (profiling)입니다. 코드가 어디에서 느린지 추측하려고 하지 마세요. 잘못 추측할 테니까요. 코드가 어디에서 느린지 보고, 그것을 고치세요. 필터링에서는 이는 다음과 같이 해석됩니다: 놓친 스팸을 보고, 그것들을 잡기 위해 무엇을 할 수 있었는지 파악하세요.

예를 들어, 스패머들은 현재 필터를 회피하기 위해 적극적으로 노력하고 있으며, 그들이 하는 일 중 하나는 필터가 단어를 인식하지 못하도록 단어를 쪼개고 철자를 틀리게 쓰는 것입니다. 하지만 이것에 대해 작업하는 것은 저의 첫 번째 우선순위가 아닙니다. 왜냐하면 저는 여전히 이런 스팸을 잡아내는 데 어려움이 없기 때문입니다 [10].

현재 제가 어려움을 겪고 있는 스팸은 두 종류가 있습니다.

하나는 데이트 사이트에서 채팅하거나 프로필을 보라고 초대하는 여성의 이메일인 척하는 유형입니다. 이들은 판매용어가 없는 판매 유인책을 만들 수 있는 유일한 유형이기 때문에 통과됩니다. 이들은 일반 이메일과 같은 어휘를 사용합니다.

제가 필터링하기 어려운 또 다른 종류의 스팸은 불가리아 등지에서 계약 프로그래밍 서비스를 제공하는 회사들로부터 오는 것입니다. 이들은 저도 프로그래머이기 때문에 통과됩니다. 스팸은 제 실제 메일과 같은 단어로 가득 차 있습니다.

저는 아마도 개인 광고 유형에 먼저 집중할 것입니다. 더 자세히 살펴보면 이들과 제 실제 메일 사이에 통계적 차이를 찾을 수 있을 것 같습니다. 글쓰기 스타일은 분명히 다르지만, 이를 잡아내려면 다중 단어 필터링 (multiword filtering)이 필요할 수 있습니다. 또한, 그들은 URL을 반복하는 경향이 있는데, 합법적인 메일에 URL을 포함하는 사람은 그렇게 하지 않을 것입니다 [11].

아웃소싱 유형은 잡기 어려울 것입니다. 사이트에 크롤러를 보내더라도 결정적인 통계적 증거를 찾지 못할 것입니다. 아마도 유일한 해결책은 스팸에서 광고되는 도메인들의 중앙 목록일 것입니다 [12]. 하지만 이런 유형의 메일이 그렇게 많지는 않을 것입니다. 만약 남아있는 스팸이 불가리아로부터 온 계약 프로그래밍 서비스의 원치 않는 제안뿐이라면, 우리 모두는 아마 다른 일을 하러 갈 수 있을 것입니다.

통계적 필터링이 실제로 우리를 그 지점까지 데려갈까요? 저는 모릅니다. 지금 당장은 저 개인적으로 스팸은 문제가 아닙니다. 하지만 스패머들은 아직 통계적 필터를 속이기 위한 진지한 노력을 하지 않았습니다. 그들이 그렇게 할 때 무슨 일이 일어날까요?

저는 네트워크 수준에서 작동하는 필터에 대해서는 낙관적이지 않습니다 [13]. 돌파할 가치가 있는 정적인 장애물이 있다면, 스패머들은 그것을 돌파하는 데 매우 효율적입니다. 이미 Assurance Systems라는 회사가 있는데, 그들은 여러분의 메일을 Spamassassin을 통해 실행하고 그것이 필터링될지 여부를 알려줄 것입니다.

네트워크 수준 필터가 완전히 쓸모없지는 않을 것입니다. 그것들은 Virtumundo나 Equalamail처럼 자신들이 옵트인 (opt-in) 목록을 운영한다고 주장하는 회사들의 '옵트인' 스팸을 모두 없애는 데 충분할 수도 있습니다. 이런 것들은 본문 내용과 상관없이 헤더만으로 필터링할 수 있습니다. 하지만 헤더를 위조하거나 오픈 릴레이 (open relay)를 사용할 의향이 있는 사람이라면, 아마도 대부분의 포르노 스패머를 포함하여, 원한다면 네트워크 수준 필터를 통과시켜 메시지를 보낼 수 있을 것입니다. (그들이 보내고 싶은 메시지는 결코 아닐지라도, 무엇이든 말입니다.)

제가 낙관적으로 생각하는 종류의 필터는 각 개별 사용자의 메일을 기반으로 확률을 계산하는 필터입니다. 이것들은 오탐을 피하는 것뿐만 아니라 필터링에서도 훨씬 더 효과적일 수 있습니다. 예를 들어, 메시지 어디에서든 Base64 인코딩된 수신자의 이메일 주소를 찾는 것은 매우 좋은 스팸 지표입니다.

하지만 개별 필터의 진정한 장점은 모두 다를 것이라는 점입니다. 모든 필터의 확률이 다르다면, 스패머의 최적화 루프, 즉 프로그래머들이 말하는 편집-컴파일-테스트 (edit-compile-test) 주기는 끔찍하게 느려질 것입니다. 데스크톱에 있는 필터 복사본을 통과할 때까지 스팸을 조작하는 대신, 각 조작마다 테스트 메일을 보내야 할 것입니다. 이는 대화형 최상위 (interactive toplevel)가 없는 언어로 프로그래밍하는 것과 같을 것이며, 저는 누구에게도 그런 경험을 바라지 않을 것입니다.

## 각주 (Notes)

[1] 폴 그레이엄 (Paul Graham). "스팸에 대한 계획 (A Plan for Spam)." 2002년 8월. http://paulgraham.com/spam.html. 이 알고리즘의 확률은 베이즈 정리 (Bayes' Rule)의 퇴화된 경우를 사용하여 계산됩니다. 두 가지 단순화 가정이 있습니다: 특징 (즉, 단어)의 확률이 독립적이라는 것과 이메일이 스팸일 사전 확률 (prior probability)에 대해 아무것도 모른다는 것입니다. 첫 번째 가정은 텍스트 분류에서 널리 퍼져 있습니다. 이를 사용하는 알고리즘을 "나이브 베이지안 (naive Bayesian)"이라고 부릅니다. 두 번째 가정은 제 수신 메일에서 스팸의 비율이 날마다 (실제로 시간마다) 너무 많이 변동하여 전체 사전 비율이 예측 변수로서 가치가 없다고 생각했기 때문에 제가 세운 것입니다. P(스팸)과 P(비스팸)이 모두 0.5라고 가정하면, 서로 상쇄되어 공식에서 제거할 수 있습니다. 스팸 대 비스팸 비율이 지속적으로 매우 높거나 (특히) 매우 낮은 상황에서 베이지안 필터링을 하고 있다면, 사전 확률을 통합하여 필터 성능을 개선할 수 있을 것입니다. 이를 올바르게 수행하려면 시간대별 비율을 추적해야 합니다. 왜냐하면 스팸 및 합법적인 메일 볼륨 모두 뚜렷한 일일 패턴을 가지고 있기 때문입니다.

[2] 패트릭 판텔 (Patrick Pantel) 및 데캉 린 (Dekang Lin). "스팸콥 - 스팸 분류 및 조직 프로그램 (SpamCop-- A Spam Classification & Organization Program)." AAAI-98 텍스트 분류 학습 워크숍 (AAAI-98 Workshop on Learning for Text Categorization) 회의록.

[3] 메란 사하미 (Mehran Sahami), 수잔 듀메이 (Susan Dumais), 데이비드 헤커만 (David Heckerman), 에릭 호르비츠 (Eric Horvitz). "정크 이메일 필터링에 대한 베이지안 접근 방식 (A Bayesian Approach to Filtering Junk E-Mail)." AAAI-98 텍스트 분류 학습 워크숍 (AAAI-98 Workshop on Learning for Text Categorization) 회의록.

[4] 당시 저는 약 4,000통의 합법적인 이메일 중 오탐이 전혀 없었습니다. 다음 합법적인 이메일이 오탐이었다면, 이는 0.03%를 의미했을 것입니다. 이러한 오탐률은 제가 나중에 설명하겠지만 신뢰할 수 없습니다. 제가 여기서 수치를 인용하는 이유는 오탐률이 얼마든 간에 1.16% 미만이라는 점을 강조하기 위함입니다.

[5] 빌 예라주니스 (Bill Yerazunis). "희소 이진 다항식 해시 메시지 필터링 및 CRM114 디스크리미네이터 (Sparse Binary Polynomial Hash Message Filtering and The CRM114 Discriminator)." 2003년 스팸 컨퍼런스 (2003 Spam Conference) 회의록.

[6] '스팸에 대한 계획 (A Plan for Spam)'에서는 0.99와 0.01의 임계값을 사용했습니다. 코퍼스의 크기에 비례하는 임계값을 사용하는 것이 정당해 보입니다. 현재 각 유형의 메일이 약 10,000개 정도 있으므로, 저는 0.9999와 0.0001을 사용합니다.

[7] 여기에 제가 수정해야 할 결함이 있습니다. 현재 'Subject*foo'가 'foo'로 퇴화할 때, 이는 제가 표시하는 헤더 줄을 제외한 본문 또는 헤더 줄에 'foo'가 나타나는 통계를 얻는다는 의미입니다. 제가 해야 할 일은 'foo'에 대한 통계를 특정 버전과 함께 전체적으로 추적하고, 'Subject*foo'에서 'foo'로 퇴화하는 것이 아니라 'Anywhere*foo'로 퇴화하는 것입니다. 대소문자의 경우도 마찬가지입니다: 대문자에서 소문자로 퇴화하는 것이 아니라 어떤 경우든 퇴화해야 합니다. 가격에 대해서도 이렇게 하는 것이 아마 이득이 될 것입니다. 예를 들어, '$129.99'에서 '$--9.99', '$--.99', '$--'로 퇴화하는 것입니다. 단어를 어간으로 퇴화할 수도 있지만, 이는 작은 코퍼스를 가졌을 때 초기에만 필터링률을 향상시킬 것입니다.

[8] 스티븐 하우저 (Steven Hauser). "통계적 스팸 필터가 저에게 효과가 있습니다 (Statistical Spam Filter Works for Me)." http://www.sofbot.com.

[9] 오탐이 모두 같은 것은 아니며, 스팸을 막는 기술을 비교할 때 이 점을 기억해야 합니다. 필터로 인해 발생하는 많은 오탐은 놓쳐도 상관없는 스팸에 가까운 메일일 것입니다. 반면, 블랙리스트 (blacklist)로 인해 발생하는 오탐은 예를 들어 잘못된 ISP를 선택한 사람들의 메일일 것입니다. 두 경우 모두 스팸에 가까운 메일을 잡아내지만, 블랙리스트의 경우 근접성은 물리적이고, 필터의 경우 텍스트적입니다.

[10] 스패머가 토큰을 가리는 데 충분히 능숙해져서 문제가 된다면, 우리는 단순히 공백, 마침표, 쉼표 등을 제거하고 사전을 사용하여 결과 시퀀스에서 단어를 추출하는 방식으로 대응할 수 있습니다. 그리고 물론, 원래 텍스트에 보이지 않던 단어를 이런 식으로 찾는 것 자체가 스팸의 증거가 될 것입니다. 단어를 추출하는 것이 간단하지는 않을 것입니다. 단순히 단어 경계를 재구성하는 것 이상이 필요할 것입니다. 스패머는 글자를 추가하기도 하고 ('xHot nPorn cSite'), 생략하기도 합니다 ('P#rn'). 인간의 시각이 이러한 속임수가 접근하는 한계이기 때문에 시각 연구가 유용할 수 있습니다.

[11] 일반적으로 스팸은 일반 이메일보다 반복적입니다. 그들은 메시지를 확실히 전달하고 싶어 합니다. 저는 현재 상위 15개 토큰에 중복을 허용하지 않습니다. 발신자가 특정 나쁜 단어를 여러 번 사용하면 오탐이 발생할 수 있기 때문입니다. (제 현재 필터에서 'dick'은 스팸 확률이 0.9999이지만, 이름이기도 합니다.) 하지만 중복을 적어도 인식해야 할 것 같습니다. 그래서 브라이언 버튼 (Brian Burton)이 SpamProbe에서 하는 것처럼 각 토큰을 최대 두 개까지 허용하는 것을 시도해 볼 수도 있습니다.

[12] 스패머가 메시지의 다른 모든 것을 생성하기 위해 매드립 (mad-lib) 기술을 사용하도록 내몰리면 Brightmail과 같은 접근 방식이 퇴화하는 지점입니다.

[13] 때때로 우리는 네트워크 수준에서 필터링 작업을 해야 한다고 주장되기도 합니다. 더 효율적이기 때문이라고 합니다. 사람들이 이렇게 말할 때 보통 의미하는 것은 다음과 같습니다: 우리는 현재 네트워크 수준에서 필터링하고 있으며, 처음부터 다시 시작하고 싶지 않습니다. 하지만 해결책에 맞춰 문제를 지시할 수는 없습니다. 역사적으로 자원 부족 논쟁은 소프트웨어 설계 논쟁에서 패배하는 쪽이었습니다. 사람들은 주로 다른 이유로 내린 결정 (특히 불활동)을 정당화하기 위해 그것을 사용하는 경향이 있습니다.

이 논문의 초고를 읽어주신 사라 할린 (Sarah Harlin), 트레버 블랙웰 (Trevor Blackwell), 그리고 댄 기핀 (Dan Giffin)에게 감사드립니다. 그리고 이 필터가 작동하는 대부분의 인프라를 제공해 주신 댄에게 다시 한번 감사드립니다.

관련: