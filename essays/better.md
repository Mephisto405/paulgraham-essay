# 더 나은 베이즈 필터링 (Better Bayesian Filtering)

2003년 1월

---

제가 여기서 소개하고 싶은 첫 번째 발견은 연구 논문을 평가하는 게으른 방식의 알고리즘입니다. 그냥 원하는 대로 쓰고 이전 연구를 전혀 인용하지 않으면, 분개한 독자들이 당신이 인용했어야 할 모든 논문의 참조를 보내줄 것입니다. 저는 'A Plan for Spam'[1]이 슬래시닷(Slashdot)에 올라온 후에 이 알고리즘을 발견했습니다.

스팸 필터링은 잘 확립된 분야인 텍스트 분류의 하위 집합이지만, 베이즈 스팸 필터링 자체에 대한 최초의 논문은 1998년 같은 컨퍼런스에서 발표된 판텔과 린(Pantel and Lin)[2]의 논문과 마이크로소프트 리서치(Microsoft Research) 그룹[3]의 논문 두 편인 것 같습니다. 이 연구에 대해 들었을 때 저는 조금 놀랐습니다. 4년 전부터 사람들이 베이즈 필터링을 사용하고 있었다면, 왜 모두가 그것을 사용하지 않았을까요?

논문을 읽고 그 이유를 알게 되었습니다. 판텔과 린의 필터가 두 논문 중 더 효과적이었지만, 스팸의 92%만 잡아냈고 오탐률(false positives)은 1.16%였습니다. 제가 베이즈 스팸 필터를 작성해 보았을 때, 오탐률 0.03% 미만으로 스팸의 99.5%를 잡아냈습니다[4]. 동일한 실험을 시도하는 두 사람이 매우 다른 결과를 얻는 것은 항상 우려스러운 일입니다. 이 두 결과 수치는 반대되는 결론을 내릴 수 있기 때문에 특히 우려스럽습니다.

사용자마다 요구사항이 다르지만, 저는 많은 사람들에게 1.16%의 오탐률을 가진 92%의 필터링 비율은 필터링이 수용 가능한 해결책이 아님을 의미하는 반면, 0.03% 미만의 오탐률을 가진 99.5%는 수용 가능함을 의미한다고 생각합니다. 그렇다면 왜 이렇게 다른 수치가 나왔을까요?

저는 판텔과 린의 결과를 재현해 보지는 않았지만, 논문을 읽어본 결과 차이를 설명할 가능성이 있는 다섯 가지를 발견했습니다. 첫째, 그들은 매우 적은 데이터, 즉 스팸 160건과 정상 메일 466건으로 필터를 학습시켰다는 점입니다. 그렇게 작은 데이터셋으로는 필터 성능이 계속 향상되어야 합니다. 따라서 그들의 수치는 베이즈 스팸 필터링 일반은 물론이고, 그들 알고리즘의 성능에 대한 정확한 측정치조차 아닐 수 있습니다.

하지만 가장 중요한 차이는 아마도 그들이 메시지 헤더를 무시했다는 점이라고 생각합니다. 스팸 필터 작업을 해본 사람이라면 누구나 이 결정이 잘못되었다고 생각할 것입니다. 하지만 제가 처음 필터를 작성할 때 저 또한 헤더를 무시했습니다. 왜 그랬을까요? 문제를 깔끔하게 유지하고 싶었기 때문입니다. 당시 저는 메일 헤더에 대해 잘 몰랐고, 헤더는 무작위적인 정보로 가득 찬 것처럼 보였습니다. 필터 작성자에게는 여기서 교훈이 있습니다: 데이터를 무시하지 마십시오. 이 교훈은 너무나 명백해서 언급할 필요도 없을 것 같지만, 저는 몇 번이고 다시 배워야 했습니다.

셋째, 판텔과 린은 토큰을 어간 추출(stemming)했습니다. 이는 예를 들어 'mailing'과 'mailed'를 모두 'mail'이라는 어근으로 축소하는 것을 의미합니다. 그들은 코퍼스의 작은 크기 때문에 이렇게 해야만 한다고 느꼈을 수도 있지만, 만약 그렇다면 이는 일종의 성급한 최적화(premature optimization)입니다.

넷째, 그들은 확률을 다르게 계산했습니다. 그들은 모든 토큰을 사용했지만, 저는 가장 중요한 15개만 사용합니다. 모든 토큰을 사용하면, 누군가가 다단계 마케팅 사업으로 부자가 된 이야기를 들려주는 종류의 긴 스팸을 놓치기 쉽습니다. 또한 그러한 알고리즘은 스패머가 속이기 쉬울 것입니다: 스팸 용어의 균형을 맞추기 위해 무작위 텍스트 덩어리를 추가하기만 하면 됩니다.

마지막으로, 그들은 오탐에 대해 편향을 두지 않았습니다. 저는 모든 스팸 필터링 알고리즘에는 필터링 비율을 희생하여 오탐률을 낮출 수 있도록 조절할 수 있는 편리한 손잡이(knob)가 있어야 한다고 생각합니다. 저는 정상 메일 코퍼스에 있는 토큰의 출현 횟수를 두 배로 계산하는 방식으로 이를 수행합니다.

스팸 필터링을 단순한 텍스트 분류 문제로 취급하는 것은 좋은 생각이 아니라고 생각합니다. 텍스트 분류 기술을 사용할 수는 있지만, 해결책은 텍스트가 이메일, 특히 스팸이라는 사실을 반영해야 하며, 또 반영해야 합니다. 이메일은 단순한 텍스트가 아닙니다. 구조를 가지고 있습니다. 스팸 필터링은 단순한 분류가 아닙니다. 오탐은 미탐(false negatives)보다 훨씬 더 나쁘기 때문에, 이를 다른 종류의 오류로 취급해야 합니다. 그리고 오류의 원인은 단순한 무작위 변동이 아니라, 당신의 필터를 무력화하기 위해 적극적으로 노력하는 실제 인간 스패머입니다.

## 토큰 (Tokens)

슬래시닷 기사 이후에 들었던 또 다른 프로젝트는 빌 예라주니스(Bill Yerazunis)의 CRM114[5]였습니다. 이것은 방금 제가 언급한 설계 원칙에 대한 반례입니다. CRM114는 단순한 텍스트 분류기이지만, 자신이 하고 있는 일이 무엇인지조차 모르는 상태에서 스팸을 거의 완벽하게 필터링할 만큼 놀랍도록 효과적입니다. CRM114가 어떻게 작동하는지 이해하고 나니, 결국 단일 단어 기반 필터링에서 이와 같은 접근 방식으로 전환해야 할 것이라는 생각이 들었습니다. 하지만 먼저, 단일 단어로 어디까지 갈 수 있을지 지켜보자고 생각했습니다. 그리고 그 답은 놀랍게도, 아주 멀리 갈 수 있다는 것이었습니다.

저는 주로 더 똑똑한 토큰화(tokenization)에 집중해 왔습니다. 현재 스팸에 대해 CRM114에 근접하는 필터링 속도를 달성할 수 있었습니다. 이러한 기술들은 대부분 빌의 기술과 상호보완적입니다. 최적의 해결책은 둘 다를 통합할 수 있습니다.

'A Plan for Spam'은 토큰에 대한 매우 간단한 정의를 사용합니다. 문자, 숫자, 대시, 아포스트로피, 달러 기호는 구성 문자(constituent characters)이며, 그 외의 모든 것은 토큰 구분자(token separator)입니다. 저는 또한 대소문자를 구분하지 않았습니다.

이제 저는 더 복잡한 토큰 정의를 가지고 있습니다:
*   대소문자를 구분합니다.
*   느낌표는 구성 문자입니다.
*   마침표와 쉼표는 두 숫자 사이에 나타나는 경우 구성 문자로 간주됩니다. 이를 통해 IP 주소와 가격을 그대로 얻을 수 있습니다.
*   $20-25와 같은 가격 범위는 $20과 $25라는 두 개의 토큰을 생성합니다.
*   To, From, Subject, Return-Path 줄 내에서 또는 URL 내에서 발생하는 토큰은 그에 따라 표시됩니다. 예를 들어, 제목 줄의 'foo'는 'Subject\*foo'가 됩니다. (별표는 구성 문자로 허용되지 않는 문자일 수 있습니다.)

이러한 조치들은 필터의 어휘(vocabulary)를 늘려 구별력(discriminating)을 높여줍니다. 예를 들어, 현재 필터에서는 제목 줄의 'free'는 스팸 확률이 98%인 반면, 본문의 같은 토큰은 스팸 확률이 65%에 불과합니다. 현재 몇 가지 확률은 다음과 같습니다[6]:

*   Subject\*FREE 0.9999
*   free!! 0.9999
*   To\*free 0.9998
*   Subject\*free 0.9782
*   free! 0.9199
*   Free 0.9198
*   Url\*free 0.9091
*   FREE 0.8747
*   From\*free 0.7636
*   free 0.6546

'Plan for Spam' 필터에서는 이 모든 토큰이 동일한 확률인 0.7602를 가졌을 것입니다. 그 필터는 약 23,000개의 토큰을 인식했지만, 현재 필터는 약 187,000개를 인식합니다.

더 큰 토큰의 우주를 갖는 단점은 놓칠 가능성이 더 많다는 것입니다. 코퍼스를 더 많은 토큰에 분산시키는 것은 코퍼스를 더 작게 만드는 것과 같은 효과를 줍니다. 예를 들어 느낌표를 구성 문자로 간주하면, 'free'와 느낌표 두 개만 있는 경우 99.99%의 확률을 가지고 있음을 알더라도, 느낌표 일곱 개가 있는 'free'에 대한 스팸 확률을 가지지 못하게 될 수 있습니다.

이에 대한 한 가지 해결책은 제가 '단계적 하향 처리(degeneration)'라고 부르는 것입니다. 토큰에 대한 정확한 일치 항목을 찾을 수 없을 때, 덜 구체적인 버전처럼 취급합니다. 저는 끝에 오는 느낌표, 대문자, 그리고 다섯 개의 표시된 컨텍스트 중 하나에 나타나는 것을 토큰을 더 구체적으로 만드는 것으로 간주합니다. 예를 들어, 'Subject\*free!'에 대한 확률을 찾지 못하면 'Subject\*free', 'free!', 'free'에 대한 확률을 찾아 0.5에서 가장 멀리 떨어진 것을 선택합니다.

필터가 제목 줄에서 'FREE!!!'를 보고 해당 확률을 가지고 있지 않을 때 고려되는 대안들은 다음과 같습니다[7]:

*   Subject\*Free!!!
*   Subject\*free!!!
*   Subject\*FREE!
*   Subject\*Free!
*   Subject\*free!
*   Subject\*FREE
*   Subject\*Free
*   Subject\*free
*   FREE!!!
*   Free!!!
*   free!!!
*   FREE!
*   Free!
*   free!
*   FREE
*   Free
*   free

이렇게 할 때는 초기 대문자 버전뿐만 아니라 전체 대문자와 전체 소문자 버전도 반드시 고려해야 합니다. 스팸은 명령형 문장이 더 많은 경향이 있으며, 이 경우 첫 단어는 동사입니다. 따라서 초기 대문자가 있는 동사는 전체 소문자보다 더 높은 스팸 확률을 가집니다. 제 필터에서는 'Act'의 스팸 확률이 98%이고 'act'의 확률은 62%에 불과합니다.

필터의 어휘를 늘리면, 이전의 '같음' 정의에 따라 동일한 단어를 여러 번 계산하게 될 수 있습니다. 논리적으로, 그들은 더 이상 같은 토큰이 아닙니다. 하지만 이것이 여전히 신경 쓰인다면, 경험상 여러 번 계산하는 것처럼 보이는 단어들이 바로 당신이 원하는 것들일 가능성이 높다는 점을 덧붙이고 싶습니다.

더 큰 어휘의 또 다른 효과는 들어오는 메일을 볼 때 더 흥미로운 토큰, 즉 확률이 0.5에서 멀리 떨어진 것들을 발견하게 된다는 것입니다. 저는 메일이 스팸인지 결정하기 위해 가장 흥미로운 15개를 사용합니다. 하지만 이렇게 고정된 숫자를 사용하면 문제가 발생할 수 있습니다. 매우 흥미로운 토큰이 많이 발견되면, 결과는 동등하게 흥미로운 토큰의 순서를 결정하는 임의의 요인에 의해 결정될 수 있습니다.

이를 처리하는 한 가지 방법은 일부를 다른 것보다 더 흥미롭게 취급하는 것입니다. 예를 들어, 'dalco' 토큰은 제 스팸 코퍼스에서 3번 발생하고 정상 메일 코퍼스에서는 전혀 발생하지 않습니다. 'Url\*optmails' (URL 내의 'optmails'를 의미) 토큰은 1223번 발생합니다. 하지만 제가 토큰의 확률을 계산했을 때, 둘 다 0.99라는 임계값으로 동일한 스팸 확률을 가졌을 것입니다. 이는 올바르지 않다고 느껴집니다. 이 두 토큰에 상당히 다른 확률을 부여해야 한다는 이론적 주장(판텔과 린은 그렇게 합니다)이 있지만, 저는 아직 시도해보지 않았습니다. 적어도 어느 한 코퍼스에만 나타나는 15개 이상의 토큰을 발견한다면, 많이 발생하는 토큰에 우선순위를 부여해야 한다는 것은 분명해 보입니다.

이제 두 개의 임계값 기준이 있습니다. 스팸 코퍼스에만 나타나는 토큰의 경우, 10회 이상 발생하면 확률은 0.9999이고 그렇지 않으면 0.9998입니다. 정상 메일 코퍼스에서만 발견되는 토큰에 대해서도 마찬가지입니다. 나중에 토큰 확률을 상당히 조정할 수도 있지만, 이 작은 조정만으로도 토큰이 올바르게 정렬되도록 보장합니다.

또 다른 가능성은 15개 토큰뿐만 아니라 특정 흥미도 임계값 이상의 모든 토큰을 고려하는 것입니다. 스티븐 하우저(Steven Hauser)는 자신의 통계 스팸 필터[8]에서 이렇게 합니다. 임계값을 사용한다면, 매우 높게 설정해야 합니다. 그렇지 않으면 스패머들이 더 무해한 단어로 메시지를 채워 넣어 당신을 속일 수 있습니다.

마지막으로, HTML에 대해서는 어떻게 해야 할까요? 저는 그것을 무시하는 것부터 전부 파싱하는 것까지 모든 옵션을 시도해 보았습니다. HTML을 무시하는 것은 나쁜 생각입니다. 유용한 스팸 신호로 가득 차 있기 때문입니다. 하지만 모든 것을 파싱하면 필터가 단순한 HTML 인식기로 전락할 수 있습니다. 가장 효과적인 접근 방식은 중간 경로를 택하는 것, 즉 일부 토큰은 알아보고 다른 토큰은 무시하는 것입니다. 저는 a, img, font 태그를 보고 나머지는 무시합니다. 링크와 이미지는 URL을 포함하고 있으므로 반드시 살펴보아야 합니다.

HTML을 더 똑똑하게 처리할 수도 있겠지만, 여기에 많은 시간을 투자할 가치는 없다고 생각합니다. HTML로 가득 찬 스팸은 필터링하기 쉽습니다. 더 똑똑한 스패머들은 이미 이를 피하고 있습니다. 따라서 향후 성능은 HTML을 어떻게 처리하는지에 크게 좌우되지 않을 것입니다.

## 성능 (Performance)

2002년 12월 10일부터 2003년 1월 10일까지 약 1750개의 스팸을 받았습니다. 이 중 4개가 통과했습니다. 이는 약 99.75%의 필터링 비율입니다. 제가 놓친 4개의 스팸 중 두 개는 우연히 제 정상 메일에서 자주 발생하는 단어를 사용했기 때문에 통과했습니다.

세 번째는 불안전한 CGI 스크립트를 악용하여 제3자에게 메일을 보내는 유형 중 하나였습니다. 헤더는 정상적이고 사용하는 단어도 신중하기 때문에 내용만으로는 필터링하기 어렵습니다. 그럼에도 불구하고 저는 보통 이를 잡아냅니다. 이 스팸은 임계값 0.9 바로 아래인 0.88의 확률로 통과했습니다. 물론, 여러 토큰 시퀀스를 살펴보면 이를 쉽게 잡아낼 수 있습니다. '피드백 양식의 결과는 다음과 같습니다'와 같은 문구는 즉각적인 단서가 됩니다.

네 번째 스팸은 제가 '미래형 스팸'이라고 부르는 것입니다. 저는 스팸이 이렇게 진화할 것이라고 예상하기 때문입니다: 완전히 중립적인 텍스트 뒤에 URL이 오는 형식입니다. 이 경우, 누군가 자신의 홈페이지를 마침내 완성했으며 제가 그것을 봐주기를 바란다는 내용이었습니다. (물론 해당 페이지는 포르노 사이트 광고였습니다.) 스패머들이 헤더에 신중하고 새로운 URL을 사용한다면, 미래형 스팸에는 필터가 알아차릴 만한 것이 없습니다. 물론 페이지를 보기 위해 크롤러를 보내는 방식으로 대응할 수 있습니다. 하지만 그것이 필요하지 않을 수도 있습니다. 미래형 스팸의 응답률은 낮아야 합니다. 그렇지 않으면 모든 사람이 이를 사용할 것입니다. 충분히 낮다면, 스패머가 이를 보내는 것이 이득이 되지 않을 것이며, 우리는 이를 필터링하는 데 너무 많은 노력을 기울일 필요가 없을 것입니다.

이제 정말 충격적인 소식입니다. 같은 한 달 동안 저는 세 개의 오탐을 받았습니다. 어떤 면에서는 오탐을 몇 개 받는 것이 안심이 됩니다. 'A Plan for Spam'을 쓸 당시에는 오탐이 전혀 없었기에, 그것이 어떤 모습일지 몰랐습니다. 이제 몇 개를 경험하고 나니, 제가 두려워했던 것만큼 나쁘지 않다는 것을 발견하고 안심했습니다. 통계 필터에서 발생하는 오탐은 스팸과 매우 비슷하게 들리는 메일인 것으로 나타나며, 이는 놓쳐도 가장 신경 쓰이지 않는 종류의 메일들입니다.

오탐 두 개는 제가 물건을 구매했던 회사들의 뉴스레터였습니다. 저는 그것들을 받도록 요청한 적이 없으므로, 논란의 여지 없이 스팸이라고 할 수 있지만, 이전에는 스팸으로 삭제하지 않았기 때문에 오탐으로 간주합니다. 필터가 이를 잡아낸 이유는 두 회사 모두 1월에 자체 서버에서 메일을 보내는 대신 상용 이메일 발송업체를 사용하기 시작했고, 헤더와 본문 모두 훨씬 더 스팸처럼 변했기 때문입니다.

하지만 세 번째 오탐은 좋지 않은 사례였습니다. 이집트의 누군가로부터 온 메일이었고 전체가 대문자로 작성되었습니다. 이는 토큰을 대소문자 구분하게 만든 직접적인 결과이며, Plan for Spam 필터라면 이를 잡아내지 못했을 것입니다.

통계적으로 노이즈 영역에 있기 때문에 전체 오탐률이 얼마인지 말하기 어렵습니다. 효과적인 필터를 작업해 본 사람이라면 누구나 이 문제를 인지하고 있을 것입니다. 어떤 이메일은 스팸인지 아닌지 구분하기 어렵고, 필터를 매우 엄격하게 설정했을 때 결국 살펴보게 되는 것들이 바로 이런 메일입니다. 예를 들어, 지금까지 필터는 오타 때문에 제 주소로 발송된 두 개의 이메일과 제가 다른 사람이라고 믿고 제게 보낸 메일 하나를 잡아냈습니다. 이러한 메일들은 제 스팸도 아니고 제 정상 메일도 아니라고 주장할 수 있습니다.

또 다른 오탐은 Virtumundo의 부사장으로부터 온 것이었습니다. 저는 고객인 척하며 그들에게 편지를 보냈고, 회신이 Virtumundo의 메일 서버를 통해 돌아왔기 때문에 상상할 수 있는 가장 결정적인 헤더를 가지고 있었습니다. 이것 또한 실제 오탐이 아니라고 주장할 수도 있지만, 일종의 하이젠베르크 불확정성 원리 효과입니다. 저는 스팸 필터링에 대해 글을 쓰고 있었기 때문에 이것을 받았습니다.

이를 제외하면, 약 7740개의 정상 메일 중에서 총 5개의 오탐을 받았으며, 이는 0.06%의 비율입니다. 나머지 두 개는 제가 구매한 물건의 주문이 지연되었다는 알림과 Evite의 파티 알림이었습니다. 표본이 매우 작다는 점과, 필터가 이 중 일부를 잡아내지 못하도록 수정할 수 있다고 생각하기 때문에 이 수치를 신뢰할 수 없다고 생각합니다.

제 생각에 오탐은 미탐과는 다른 종류의 오류입니다. 필터링 비율은 성능 측정치입니다. 저는 오탐을 버그에 더 가깝다고 생각합니다. 저는 필터링 비율 개선을 최적화로, 오탐 감소를 디버깅으로 접근합니다. 따라서 이 다섯 개의 오탐은 제 버그 목록입니다. 예를 들어, 이집트에서 온 메일은 대문자 텍스트 때문에 필터에 나이지리아 스팸처럼 보이게 하여 잡혔습니다. 이것은 정말 일종의 버그입니다. HTML의 경우와 마찬가지로, 이메일 전체가 대문자라는 것은 실제로 개념적으로 하나의 특징이며, 각 단어마다의 특징이 아닙니다. 저는 대소문자를 더 정교한 방식으로 처리해야 합니다.

그래서 이 0.06%를 어떻게 봐야 할까요? 많은 의미는 없다고 생각합니다. 작은 표본 크기를 염두에 두고 상한선으로 취급할 수도 있습니다. 하지만 이 단계에서는 베이즈 필터링의 고유한 오탐률보다는 제 구현의 버그 측정치에 가깝습니다.

## 미래 (Future)

다음은 무엇일까요? 필터링은 최적화 문제이며, 최적화의 열쇠는 프로파일링입니다. 코드의 어느 부분이 느린지 추측하지 마십시오. 잘못 추측할 것이기 때문입니다. 코드의 느린 부분을 보고 그것을 수정하십시오. 필터링에서는 이것이 다음을 의미합니다: 놓친 스팸을 보고, 그것을 잡기 위해 무엇을 할 수 있었는지 파악하는 것입니다.

예를 들어, 스패머들은 현재 필터를 회피하기 위해 공격적으로 노력하고 있으며, 그들이 하는 일 중 하나는 필터가 단어를 인식하지 못하도록 단어를 분리하거나 오타를 내는 것입니다. 하지만 저는 여전히 이러한 스팸을 잡는 데 문제가 없기 때문에, 이것에 대한 작업은 제 우선순위가 아닙니다[10].

제가 현재 어려움을 겪고 있는 스팸 유형은 두 가지입니다. 첫 번째는 데이트 사이트에서 여성과 채팅하거나 프로필을 보라고 초대하는 이메일인 척하는 유형입니다. 이들은 판매 멘트 없이도 할 수 있는 유일한 유형의 판매 제안이기 때문에 통과합니다. 이들은 일반 이메일과 같은 어휘를 사용합니다.

제가 필터링에 어려움을 겪는 또 다른 종류의 스팸은 예를 들어 불가리아의 회사들이 제공하는 계약 프로그래밍 서비스에 대한 것입니다. 저 역시 프로그래머이기 때문에 이 스팸들이 통과하며, 스팸은 제 실제 메일과 같은 단어로 가득 차 있습니다. 저는 아마도 개인 광고 유형부터 집중할 것입니다. 더 자세히 살펴보면 제 실제 메일과 이 스팸 간의 통계적 차이를 발견할 수 있을 것이라고 생각합니다. 물론 글쓰기 스타일은 다르지만, 이를 잡아내려면 다중 단어 필터링(multiword filtering)이 필요할 수 있습니다.

또한, 그들은 URL을 반복하는 경향이 있는데, 정상 메일에 URL을 포함하는 사람은 그렇게 하지 않을 것입니다[11]. 아웃소싱 유형은 잡아내기 어려울 것입니다. 사이트에 크롤러를 보내더라도 통계적으로 결정적인 증거를 찾을 수 없을 것입니다. 어쩌면 유일한 해결책은 스팸에 광고된 도메인들의 중앙 목록[12]일 것입니다. 하지만 이 유형의 메일은 그렇게 많지 않을 것입니다. 만약 남은 유일한 스팸이 불가리아의 비요청 계약 프로그래밍 서비스 제안이라면, 우리 모두는 아마 다른 일로 넘어갈 수 있을 것입니다.

통계적 필터링이 실제로 우리를 그 지점으로 데려갈 수 있을까요? 모르겠습니다. 지금 당장은 개인적으로 스팸이 문제가 되지 않습니다. 하지만 스패머들은 아직 통계 필터를 속이기 위한 진지한 노력을 하지 않았습니다. 그들이 그렇게 하면 어떻게 될까요?

저는 네트워크 수준에서 작동하는 필터에 대해 낙관적이지 않습니다[13]. 넘어서는 가치가 있는 정적인 장애물이 있을 때, 스패머들은 그것을 통과하는 데 상당히 효율적입니다. 이미 Spamassassin으로 메일을 실행하고 필터링될지 여부를 알려주는 Assurance Systems라는 회사가 있습니다.

네트워크 수준 필터가 완전히 쓸모없지는 않을 것입니다. Virtumundo 및 Equalamail과 같이 옵트인 목록을 운영한다고 주장하는 회사들의 스팸, 즉 '옵트인' 스팸을 모두 차단하기에 충분할 수 있습니다. 본문에 무엇이라고 쓰여 있든 헤더만으로도 해당 스팸을 필터링할 수 있습니다. 하지만 헤더를 위조하거나 오픈 릴레이(open relays)를 사용하려는 사람은 누구나, 아마도 대부분의 음란물 스패머를 포함하여, 원한다면 네트워크 수준 필터를 통과하는 일부 메시지를 얻을 수 있어야 합니다. (하지만 이는 그들이 보내고 싶은 메시지는 전혀 아닙니다.)

제가 낙관적으로 보는 필터 유형은 각 개별 사용자의 메일을 기반으로 확률을 계산하는 것입니다. 이는 오탐을 피하는 데뿐만 아니라 필터링에서도 훨씬 더 효과적일 수 있습니다. 예를 들어, 메시지 내 어디든 Base-64로 인코딩된 수신자 이메일 주소를 찾는 것은 매우 좋은 스팸 지표입니다.

하지만 개별 필터의 진정한 장점은 모두 다르다는 것입니다. 모든 사람의 필터가 다른 확률을 가진다면, 프로그래머들이 편집-컴파일-테스트 주기(edit-compile-test cycle)라고 부르는 스패머들의 최적화 루프는 끔찍하게 느려질 것입니다. 데스크톱에 있는 필터 복사본을 통과할 때까지 스팸을 약간 수정하는 대신, 각 수정마다 테스트 메일을 보내야 할 것입니다. 이는 인터랙티브 최상위 레벨(interactive toplevel)이 없는 언어로 프로그래밍하는 것과 같을 것이며, 누구에게도 그런 일을 겪게 하고 싶지 않습니다.

## 감사 (Thanks)

Sarah Harlin, Trevor Blackwell, Dan Giffin에게 이 논문의 초안을 검토해 준 것에 대해 감사드립니다. 또한 Dan에게는 이 필터가 실행되는 데 필요한 대부분의 인프라스트랩쳐를 제공해 준 것에 대해 다시 한번 감사드립니다.

관련:

---

## 각주 (Notes)

[^1]: Paul Graham. "A Plan for Spam." August 2002. http://paulgraham.com/spam.html.
    이 알고리즘의 확률은 베이즈 정리(Bayes' Rule)의 축약된 형태를 사용하여 계산됩니다. 두 가지 단순화 가정이 있습니다: 특징(즉, 단어)의 확률이 독립적이라는 가정과, 이메일이 스팸일 사전 확률에 대해 우리가 아무것도 모른다는 가정입니다.
    첫 번째 가정은 텍스트 분류에서 널리 퍼져 있습니다. 이 가정을 사용하는 알고리즘을 '나이브 베이즈(naive Bayesian)'라고 합니다.
    두 번째 가정은 제 받은 메일의 스팸 비율이 하루 중 (사실은 시간별로) 크게 변동했기 때문에, 전체 사전 비율이 예측자로서 가치가 없다고 판단했기 때문입니다. P(spam)과 P(nonspam)이 모두 0.5라고 가정하면, 이들은 상쇄되어 공식에서 제거할 수 있습니다.
    만약 스팸 대 정상 메일 비율이 일관되게 매우 높거나 (특히) 매우 낮은 상황에서 베이즈 필터링을 수행한다면, 사전 확률을 통합함으로써 필터 성능을 향상시킬 수 있을 것입니다. 이를 올바르게 수행하려면 하루 중 시간대별 비율을 추적해야 합니다. 왜냐하면 스팸과 정상 메일의 양 모두 뚜렷한 일별 패턴을 가지고 있기 때문입니다.

[^2]: Patrick Pantel and Dekang Lin. "SpamCop-- A Spam Classification & Organization Program." Proceedings of AAAI-98 Workshop on Learning for Text Categorization.

[^3]: Mehran Sahami, Susan Dumais, David Heckerman and Eric Horvitz. "A Bayesian Approach to Filtering Junk E-Mail." Proceedings of AAAI-98 Workshop on Learning for Text Categorization.

[^4]: 당시 저는 약 4,000개의 정상 메일에 대해 오탐이 0개였습니다. 다음 정상 메일이 오탐이라면, 이는 0.03%를 제공할 것입니다. 나중에 설명하듯이 이러한 오탐률은 신뢰할 수 없습니다. 저는 오탐률이 얼마이든 1.16%보다 낮다는 것을 강조하기 위해 여기에 숫자를 인용합니다.

[^5]: Bill Yerazunis. "Sparse Binary Polynomial Hash Message Filtering and The CRM114 Discriminator." Proceedings of 2003 Spam Conference.

[^6]: "A Plan for Spam"에서는 0.99와 0.01의 임계값을 사용했습니다. 코퍼스의 크기에 비례하여 임계값을 사용하는 것은 정당화될 수 있는 것 같습니다. 이제 각 유형의 메일을 약 10,000개 가지고 있으므로 0.9999와 0.0001을 사용합니다.

[^7]: 여기서 수정해야 할 결함이 있습니다. 현재 'Subject\*foo'가 단순히 'foo'로 퇴화될 때, 이는 제가 표시하는 줄을 제외한 다른 헤더 줄 또는 본문에서 'foo'의 출현 통계를 얻는다는 것을 의미합니다.
    제가 해야 할 일은 'foo' 전체에 대한 통계뿐만 아니라 특정 버전에 대한 통계도 추적하고, 'Subject\*foo'에서 'foo'가 아닌 'Anywhere\*foo'로 퇴화시키는 것입니다. 대소문자도 마찬가지입니다: 소문자가 아닌 대문자에서 일반 대문자로 퇴화시켜야 합니다.
    가격에 대해서도 이렇게 하는 것이 좋을 것입니다. 예를 들어 '$129.99'를 '$--9.99', '$--.99', '$--'로 퇴화시키는 것입니다.
    단어에서 어간으로 퇴화시킬 수도 있지만, 이는 코퍼스가 작을 때 초기에는 필터링 속도를 향상시킬 수 있을 것입니다.

[^8]: Steven Hauser. "Statistical Spam Filter Works for Me." http://www.sofbot.com.

[^9]: 오탐은 모두 같지 않으며, 스팸 차단 기술을 비교할 때 이를 기억해야 합니다.
    필터가 유발하는 많은 오탐은 놓쳐도 괜찮은 스팸에 가까운 메일일 것이지만, 예를 들어 블랙리스트(blacklists)가 유발하는 오탐은 단순히 잘못된 ISP를 선택한 사람들의 메일일 것입니다. 두 경우 모두 스팸에 가까운 메일을 잡지만, 블랙리스트의 경우 가까움은 물리적인 것이고 필터의 경우 텍스트적인 것입니다.

[^10]: 스패머들이 단어 토큰을 모호하게 만드는 데 충분히 능숙해져서 이것이 문제가 된다면, 우리는 단순히 공백, 마침표, 쉼표 등을 제거하고 결과 시퀀스에서 단어를 골라내기 위해 사전을 사용하여 대응할 수 있습니다.
    물론 원래 텍스트에는 보이지 않았던 단어를 이런 식으로 찾는 것 자체가 스팸의 증거가 될 것입니다. 단어를 골라내는 것이 간단하지는 않을 것입니다. 단어 경계를 재구성하는 것 이상이 필요할 것입니다. 스패머들은 문자를 추가('xHot nPorn cSite')하기도 하고 생략('P#rn')하기도 합니다.
    이러한 속임수가 접근할 한계는 인간의 시각이므로 시각 연구가 여기서 유용할 수 있습니다.

[^11]: 일반적으로 스팸은 일반 이메일보다 반복적입니다. 그들은 메시지를 반복해서 전달하고 싶어합니다. 현재 저는 상위 15개 토큰에서 중복을 허용하지 않습니다. 왜냐하면 발신자가 특정 나쁜 단어를 여러 번 사용하는 경우 오탐을 받을 수 있기 때문입니다. (제 현재 필터에서는 'dick'이 0.9999의 스팸 확률을 가지지만, 이름이기도 합니다.)
    적어도 중복을 알아차리는 것이 좋다고 생각하므로, Brian Burton이 SpamProbe에서 하는 것처럼 각 토큰을 최대 두 개까지 허용하는 것을 시도할 수도 있습니다.

[^12]: 이것은 스패머들이 나머지 모든 메시지를 생성하기 위해 매드립 기법(mad-lib techniques)을 사용하도록 강요받으면 Brightmail의 접근 방식이 결국 이것으로 퇴화할 것입니다.

[^13]: 효율성이 더 높기 때문에 네트워크 수준에서 필터링 작업을 해야 한다고 주장되기도 합니다. 사람들이 보통 이렇게 말할 때 의미하는 바는 다음과 같습니다: 우리는 현재 네트워크 수준에서 필터링하고 있으며, 처음부터 다시 시작하고 싶지 않다는 것입니다.
    하지만 문제에 맞춰 해결책을 만들 수는 없습니다. 역사적으로 부족한 리소스 논쟁은 소프트웨어 설계 토론에서 패배한 쪽이었습니다. 사람들은 종종 다른 이유로 만들어진 선택(특히 비활동)을 정당화하기 위해 그것들을 사용합니다.